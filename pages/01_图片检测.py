import streamlit as st
import cv2
import numpy as np
import os
import time
import json
import zipfile
from datetime import datetime
import pandas as pd
from ultralytics import YOLO

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å›¾ç‰‡æ£€æµ‹ - YOLOv11",
    page_icon="ğŸ–¼ï¸",
    layout="wide"
)

# ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
os.makedirs("custom_models", exist_ok=True)
os.makedirs("detection_results", exist_ok=True)
os.makedirs("detection_logs", exist_ok=True)

# åˆå§‹åŒ–session_state
if "model" not in st.session_state:
    st.session_state.model = None
if "model_path" not in st.session_state:
    st.session_state.model_path = ""
if "batch_results" not in st.session_state:
    st.session_state.batch_results = []
if "preprocessed_imgs" not in st.session_state:
    st.session_state.preprocessed_imgs = []
if "detection_completed" not in st.session_state:
    st.session_state.detection_completed = False
if "last_upload_count" not in st.session_state:
    st.session_state.last_upload_count = 0


def load_model(model_path: str) -> YOLO:
    """åŠ è½½æ¨¡å‹å¹¶é¢„çƒ­"""
    if st.session_state.model is not None and st.session_state.model_path == model_path:
        return st.session_state.model

    try:
        with st.spinner(f"æ­£åœ¨åŠ è½½æ¨¡å‹ {os.path.basename(model_path)}..."):
            model = YOLO(model_path)
            # æ¨¡å‹é¢„çƒ­
            warmup_img = np.zeros((640, 640, 3), dtype=np.uint8)
            model(warmup_img, conf=0.5, verbose=False)

            st.session_state.model = model
            st.session_state.model_path = model_path
            st.success(f"æ¨¡å‹åŠ è½½å®Œæˆ: {os.path.basename(model_path)}")
            return model
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None


def batch_preprocess_images(uploaded_files):
    """æ‰¹é‡é¢„å¤„ç†å›¾ç‰‡"""
    preprocessed_list = []
    progress = st.progress(0)
    status_text = st.empty()

    for i, file in enumerate(uploaded_files):
        status_text.text(f"é¢„å¤„ç†ç¬¬ {i + 1}/{len(uploaded_files)} å¼ å›¾ç‰‡...")

        try:
            file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            if image is None:
                raise Exception("æ— æ³•è§£æå›¾ç‰‡")

            # è½¬æ¢ä¸ºRGB
            if image.shape[-1] == 3:
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            else:
                image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)

            # é™åˆ¶æœ€å¤§å°ºå¯¸
            max_size = 1280
            h, w = image_rgb.shape[:2]
            if max(h, w) > max_size:
                scale = max_size / max(h, w)
                image_rgb = cv2.resize(image_rgb, (int(w * scale), int(h * scale)))

            preprocessed_list.append({
                "original_name": file.name,
                "image_rgb": image_rgb,
                "valid": True
            })
        except Exception as e:
            preprocessed_list.append({
                "original_name": file.name,
                "error": str(e),
                "valid": False
            })

        progress.progress((i + 1) / len(uploaded_files))
        file.seek(0)

    progress.empty()
    status_text.empty()
    return preprocessed_list


def detect_batch(model, preprocessed_imgs, conf_threshold):
    """æ‰¹é‡æ£€æµ‹å›¾ç‰‡"""
    results = []
    total = len(preprocessed_imgs)
    progress = st.progress(0)
    status_text = st.empty()

    for i, img_data in enumerate(preprocessed_imgs):
        if not img_data["valid"]:
            results.append(None)
            progress.progress((i + 1) / total)
            continue

        status_text.text(f"æ£€æµ‹ç¬¬ {i + 1}/{total} å¼ å›¾ç‰‡: {img_data['original_name']}")

        try:
            # æ‰§è¡Œæ£€æµ‹
            start_time = time.time()
            detect_result = model(
                img_data["image_rgb"],
                conf=conf_threshold,
                imgsz=640,
                verbose=False,
                device="auto"
            )
            processing_time = time.time() - start_time

            # å¯è§†åŒ–ç»“æœ
            visualized_img = detect_result[0].plot(conf=True, line_width=2)

            # è§£ææ£€æµ‹ç»“æœ
            detected_texts = []
            for box in detect_result[0].boxes:
                cls_id = int(box.cls)
                cls_name = model.names[cls_id]
                if any(keyword in cls_name.lower() for keyword in ["text", "word", "character"]):
                    detected_texts.append({
                        "class": cls_name,
                        "confidence": float(box.conf),
                        "bbox": tuple(map(int, box.xyxy[0])),
                        "width": int(box.xyxy[0][2] - box.xyxy[0][0]),
                        "height": int(box.xyxy[0][3] - box.xyxy[0][1])
                    })

            # ä¿å­˜ç»“æœæ–‡ä»¶
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            name_base = os.path.splitext(img_data["original_name"])[0]
            media_path = os.path.join("detection_results", f"{name_base}_det_{timestamp}.jpg")
            meta_path = os.path.join("detection_logs", f"{name_base}_meta_{timestamp}.json")

            cv2.imwrite(media_path, visualized_img)
            with open(meta_path, 'w') as f:
                json.dump({
                    "timestamp": timestamp,
                    "original_name": img_data["original_name"],
                    "detections": detected_texts,
                    "count": len(detected_texts),
                    "processing_time": round(processing_time, 2)
                }, f, indent=2)

            results.append({
                "original_name": img_data["original_name"],
                "visualized_img": visualized_img,
                "detected_texts": detected_texts,
                "processing_time": processing_time,
                "media_path": media_path,
                "meta_path": meta_path
            })
        except Exception as e:
            st.error(f"å¤„ç† {img_data['original_name']} æ—¶å‡ºé”™: {str(e)}")
            results.append(None)

        progress.progress((i + 1) / total)

    progress.empty()
    status_text.empty()
    return results


def save_batch_zip(batch_results):
    """æ‰¹é‡ä¿å­˜ä¸ºZIP"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    zip_path = os.path.join("detection_results", f"batch_{timestamp}.zip")

    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for res in batch_results:
            if res is not None:
                zipf.write(res["media_path"], os.path.basename(res["media_path"]))
                zipf.write(res["meta_path"], os.path.basename(res["meta_path"]))

    return zip_path


def main():
    st.title("ğŸ–¼ï¸ å›¾ç‰‡æ–‡æœ¬æ£€æµ‹")
    st.markdown("æ”¯æŒæ‰¹é‡å›¾ç‰‡æ£€æµ‹ä¸æ–‡æœ¬è¯†åˆ«")

    # ä¾§è¾¹æ é…ç½® - ä¼˜åŒ–åçš„æ¨¡å‹è®¾ç½®
    with st.sidebar:
        st.header("æ¨¡å‹é…ç½®")
        # ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹
        model_file = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹ (.pt)", type=["pt"])
        model_path = None
        model = None
        if model_file:
            # ä¿å­˜ä¸Šä¼ çš„æ¨¡å‹æ–‡ä»¶
            model_path = os.path.join("custom_models", model_file.name)
            with open(model_path, "wb") as f:
                f.write(model_file.getbuffer())
            # åŠ è½½æ¨¡å‹
            model = load_model(model_path)
        else:
            # æœªä¸Šä¼ æ¨¡å‹æ—¶æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.info("è¯·ä¸Šä¼ ä½ çš„YOLOæ¨¡å‹æ–‡ä»¶ (.pt)")
        # åŠ è½½æ¨¡å‹
        model = None
        if model_path:
            model = load_model(model_path)

        # æ¨ç†å‚æ•°
        st.header("æ¨ç†å‚æ•°")
        conf_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.2, 1.0, 0.5, 0.05)
        max_images = st.slider("æœ€å¤§æ‰¹é‡å¤„ç†æ•°é‡", 1, 20, 5)

    # ä¸»å†…å®¹åŒº
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ä¸Šä¼ å›¾ç‰‡")
        uploaded_files = st.file_uploader(
            "æ”¯æŒæ ¼å¼: JPG, PNG, BMP",
            type=["jpg", "jpeg", "png", "bmp"],
            accept_multiple_files=True
        )

        # é™åˆ¶ä¸Šä¼ æ•°é‡
        if uploaded_files and len(uploaded_files) > max_images:
            uploaded_files = uploaded_files[:max_images]
            st.warning(f"å·²è‡ªåŠ¨é™åˆ¶ä¸º {max_images} å¼ å›¾ç‰‡")

        # é¢„å¤„ç†å›¾ç‰‡
        if uploaded_files and len(uploaded_files) != st.session_state.last_upload_count:
            st.session_state.preprocessed_imgs = batch_preprocess_images(uploaded_files)
            st.session_state.last_upload_count = len(uploaded_files)
            st.session_state.detection_completed = False
            st.session_state.batch_results = []

        # æ˜¾ç¤ºé¢„å¤„ç†ç»“æœ
        valid_count = sum(1 for img in st.session_state.preprocessed_imgs if img.get("valid", False))
        if st.session_state.preprocessed_imgs:
            st.info(f"å·²é¢„å¤„ç† {valid_count}/{len(st.session_state.preprocessed_imgs)} å¼ æœ‰æ•ˆå›¾ç‰‡")

            # æ˜¾ç¤ºç¼©ç•¥å›¾
            if valid_count > 0:
                cols = st.columns(3)
                for i, img_data in enumerate(st.session_state.preprocessed_imgs[:9]):
                    if img_data.get("valid", False):
                        with cols[i % 3]:
                            thumb = cv2.resize(img_data["image_rgb"], (100, 100))
                            st.image(thumb, caption=img_data["original_name"], use_container_width=True)

        # æ£€æµ‹æŒ‰é’®
        if uploaded_files and model and valid_count > 0:
            if st.button("å¼€å§‹æ‰¹é‡æ£€æµ‹", use_container_width=True, type="primary"):
                st.session_state.detection_completed = False
                with st.spinner("æ­£åœ¨è¿›è¡Œæ‰¹é‡æ£€æµ‹ï¼Œè¯·ç¨å€™..."):
                    st.session_state.batch_results = detect_batch(
                        model,
                        st.session_state.preprocessed_imgs,
                        conf_threshold
                    )
                st.session_state.detection_completed = True
                st.success("æ‰¹é‡æ£€æµ‹å®Œæˆï¼")

    with col2:
        st.subheader("æ£€æµ‹ç»“æœ")

        if st.session_state.detection_completed and st.session_state.batch_results:
            # è¿‡æ»¤æ— æ•ˆç»“æœ
            valid_results = [res for res in st.session_state.batch_results if res is not None]

            if not valid_results:
                st.error("æ²¡æœ‰æœ‰æ•ˆçš„æ£€æµ‹ç»“æœ")
            else:
                # é€‰æ‹©è¦æŸ¥çœ‹çš„å›¾ç‰‡
                selected_idx = st.selectbox(
                    "é€‰æ‹©å›¾ç‰‡",
                    range(len(valid_results)),
                    format_func=lambda x: valid_results[x]["original_name"]
                )
                current = valid_results[selected_idx]

                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                st.image(
                    current["visualized_img"],
                    caption=f"{current['original_name']} (è€—æ—¶: {current['processing_time']:.2f}s)",
                    use_container_width=True
                )

                # æ˜¾ç¤ºæ£€æµ‹è¯¦æƒ…
                with st.expander("æŸ¥çœ‹æ£€æµ‹è¯¦æƒ…", expanded=False):
                    if current["detected_texts"]:
                        st.dataframe(
                            pd.DataFrame(current["detected_texts"]),
                            use_container_width=True
                        )
                    else:
                        st.info("æœªæ£€æµ‹åˆ°æ–‡æœ¬")

                # ä¿å­˜å’Œä¸‹è½½åŠŸèƒ½
                col_save1, col_save2 = st.columns(2)
                with col_save1:
                    if st.button("ä¿å­˜å½“å‰ç»“æœ", use_container_width=True):
                        with open(current["media_path"], "rb") as f:
                            st.download_button(
                                "ä¸‹è½½å½“å‰å›¾ç‰‡",
                                f,
                                file_name=os.path.basename(current["media_path"]),
                                use_container_width=True
                            )

                with col_save2:
                    if len(valid_results) > 1 and st.button("æ‰¹é‡ä¿å­˜æ‰€æœ‰ç»“æœ", use_container_width=True):
                        with st.spinner("æ­£åœ¨æ‰“åŒ…æ‰€æœ‰ç»“æœ..."):
                            zip_path = save_batch_zip(valid_results)
                        st.success(f"å·²æ‰“åŒ… {len(valid_results)} ä¸ªç»“æœ")
                        with open(zip_path, "rb") as f:
                            st.download_button(
                                "ä¸‹è½½æ‰¹é‡ç»“æœ",
                                f,
                                file_name=os.path.basename(zip_path),
                                use_container_width=True
                            )
        else:
            if model and uploaded_files and valid_count > 0:
                st.info("ç‚¹å‡»ã€å¼€å§‹æ‰¹é‡æ£€æµ‹ã€æŒ‰é’®å¼€å§‹å¤„ç†")
            elif not model:
                st.info("è¯·å…ˆåœ¨å·¦ä¾§åŠ è½½æ¨¡å‹")
            elif not uploaded_files:
                st.info("è¯·ä¸Šä¼ å›¾ç‰‡åå¼€å§‹æ£€æµ‹")
            else:
                st.warning("æ²¡æœ‰æœ‰æ•ˆçš„å›¾ç‰‡å¯æ£€æµ‹")


if __name__ == "__main__":
    main()
