import streamlit as st
import cv2
import numpy as np
import os
import time
import json
import tempfile
from datetime import datetime
import pandas as pd
import queue
import matplotlib.pyplot as plt
from ultralytics import YOLO
import threading

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ‘„åƒå¤´æ£€æµ‹ - YOLOv11",
    page_icon="ğŸ“¹",
    layout="wide"
)

# ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
os.makedirs("custom_models", exist_ok=True)
os.makedirs("detection_results", exist_ok=True)
os.makedirs("detection_logs", exist_ok=True)

# åˆå§‹åŒ–session_state
if "model" not in st.session_state:
    st.session_state.model = None
if "model_path" not in st.session_state:
    st.session_state.model_path = "yolov11s.pt"
if "detection_active" not in st.session_state:
    st.session_state.detection_active = False
if "recording_active" not in st.session_state:
    st.session_state.recording_active = False
if "camera_recording_result" not in st.session_state:
    st.session_state.camera_recording_result = None


def load_model(model_path: str) -> YOLO:
    """åŠ è½½æ¨¡å‹å¹¶é¢„çƒ­"""
    if st.session_state.model is not None and st.session_state.model_path == model_path:
        return st.session_state.model

    try:
        with st.spinner(f"æ­£åœ¨åŠ è½½æ¨¡å‹ {os.path.basename(model_path)}..."):
            model = YOLO(model_path)
            # æ¨¡å‹é¢„çƒ­
            warmup_img = np.zeros((640, 640, 3), dtype=np.uint8)
            model(warmup_img, conf=0.5, verbose=False)

            st.session_state.model = model
            st.session_state.model_path = model_path
            st.success(f"æ¨¡å‹åŠ è½½å®Œæˆ: {os.path.basename(model_path)}")
            return model
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        return None


def camera_detection_loop(model: YOLO, conf_threshold: float, frame_queue, stop_event, record_event):
    """æ‘„åƒå¤´æ£€æµ‹å¾ªç¯"""
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)  # 0è¡¨ç¤ºé»˜è®¤æ‘„åƒå¤´

    # è·å–æ‘„åƒå¤´å‚æ•°
    fps = cap.get(cv2.CAP_PROP_FPS) or 30  # é»˜è®¤ä¸º30FPS
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # è§†é¢‘å½•åˆ¶ç›¸å…³
    out = None
    temp_file = None
    detection_stats = {}
    frame_count = 0

    try:
        while not stop_event.is_set():
            ret, frame = cap.read()
            if not ret:
                frame_queue.put(("error", "æ— æ³•è·å–æ‘„åƒå¤´ç”»é¢"))
                break

            # æ¨ç†
            results = model(frame, conf=conf_threshold, verbose=False)

            # å¯è§†åŒ–
            visualized_frame = results[0].plot(conf=True, line_width=2)

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            frame_count += 1
            for box in results[0].boxes:
                cls_id = int(box.cls)
                cls_name = results[0].names[cls_id]
                if any(keyword in cls_name.lower() for keyword in ["text", "word", "character"]):
                    if cls_name in detection_stats:
                        detection_stats[cls_name] += 1
                    else:
                        detection_stats[cls_name] = 1

            # å¤„ç†å½•åˆ¶
            if record_event.is_set():
                if out is None:
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    out = cv2.VideoWriter(temp_file.name, fourcc, fps, (width, height))

                out.write(visualized_frame)
            elif out is not None:
                # åœæ­¢å½•åˆ¶æ—¶é‡Šæ”¾èµ„æº
                out.release()
                out = None

            # å‘é€å¤„ç†åçš„å¸§åˆ°ä¸»çº¿ç¨‹
            frame_queue.put(("frame", visualized_frame, detection_stats.copy(), frame_count, fps))

            # æ§åˆ¶å¸§ç‡
            time.sleep(0.01)

    finally:
        # é‡Šæ”¾èµ„æº
        cap.release()
        if out is not None:
            out.release()

        # å‘é€ç»“æŸä¿¡å·
        if temp_file:
            frame_queue.put(("recording_complete", temp_file.name, detection_stats, frame_count, fps))
        frame_queue.put(("done",))


def save_camera_recording(video_path: str, stats: dict, frame_count: int, fps: float) -> tuple[str, str]:
    """ä¿å­˜æ‘„åƒå¤´å½•åˆ¶ç»“æœï¼ˆä¸å›¾ç‰‡/è§†é¢‘æ£€æµ‹ä¿æŒä¸€è‡´çš„é€»è¾‘ï¼‰"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = f"camera_recording_{timestamp}"

    # å¤åˆ¶å½•åˆ¶çš„è§†é¢‘
    dest_path = os.path.join("detection_results", f"{base_name}.mp4")
    with open(video_path, 'rb') as f_in, open(dest_path, 'wb') as f_out:
        f_out.write(f_in.read())

    # ä¿å­˜å…ƒæ•°æ®ï¼ˆæ ¼å¼ä¸å›¾ç‰‡/è§†é¢‘æ£€æµ‹ä¸€è‡´ï¼‰
    meta_path = os.path.join("detection_logs", f"{base_name}_meta.json")
    with open(meta_path, 'w') as f:
        json.dump({
            "timestamp": timestamp,
            "original_name": f"camera_recording_{timestamp}",
            "media_path": dest_path,
            "duration": frame_count / fps if fps > 0 else 0,
            "total_frames": frame_count,
            "fps": fps,
            "detection_stats": stats,
            "total_detections": sum(stats.values()) if stats else 0
        }, f, indent=2)

    return dest_path, meta_path


def main():
    st.title("ğŸ“¹ æ‘„åƒå¤´æ–‡æœ¬æ£€æµ‹")
    st.markdown("å®æ—¶æ‘„åƒå¤´æ–‡æœ¬æ£€æµ‹ä¸å½•åˆ¶")

    # ä¾§è¾¹æ é…ç½® - ä¼˜åŒ–åçš„æ¨¡å‹è®¾ç½®
    with st.sidebar:
        st.header("æ¨¡å‹é…ç½®")

        # ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹
        model_file = st.file_uploader("ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹ (.pt)", type=["pt"])
        model_path = None
        model = None

        if model_file:
            # ä¿å­˜ä¸Šä¼ çš„æ¨¡å‹æ–‡ä»¶
            model_path = os.path.join("custom_models", model_file.name)
            with open(model_path, "wb") as f:
                f.write(model_file.getbuffer())

            # åŠ è½½æ¨¡å‹
            model = load_model(model_path)
        else:
            # æœªä¸Šä¼ æ¨¡å‹æ—¶æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.info("è¯·ä¸Šä¼ ä½ çš„YOLOæ¨¡å‹æ–‡ä»¶ (.pt)")

        # æ¨ç†å‚æ•°
        st.header("æ¨ç†å‚æ•°")
        conf_threshold = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.01, 1.0, 0.5, 0.05)

        # æ˜¾ç¤ºé€‰é¡¹
        st.header("æ˜¾ç¤ºé€‰é¡¹")
        show_stats = st.checkbox("æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡", value=True)

    # ä¸»å†…å®¹åŒº
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("æ‘„åƒå¤´æ§åˆ¶")

        # æ§åˆ¶æŒ‰é’®
        col_btn1, col_btn2 = st.columns(2)
        start_btn = col_btn1.button("å¼€å§‹æ£€æµ‹", use_container_width=True)
        stop_btn = col_btn2.button("åœæ­¢æ£€æµ‹", use_container_width=True)

        # å½•åˆ¶æ§åˆ¶
        record_btn = st.button("å¼€å§‹/åœæ­¢å½•åˆ¶", use_container_width=True)

        # çŠ¶æ€æ˜¾ç¤º
        status_placeholder = st.empty()

        if st.session_state.detection_active:
            status_placeholder.info("çŠ¶æ€: æ­£åœ¨æ£€æµ‹...")
        else:
            status_placeholder.info("çŠ¶æ€: æœªæ£€æµ‹")

        if st.session_state.recording_active:
            status_placeholder.error("çŠ¶æ€: æ­£åœ¨æ£€æµ‹å¹¶å½•åˆ¶...")

    with col2:
        st.subheader("å®æ—¶æ£€æµ‹ç”»é¢")
        frame_placeholder = st.empty()
        stats_placeholder = st.empty()

        # å¤„ç†å¼€å§‹æ£€æµ‹
        if start_btn and not st.session_state.detection_active and st.session_state.model:
            st.session_state.detection_active = True
            st.session_state.recording_active = False
            st.session_state.camera_recording_result = None

            # åˆ›å»ºé€šä¿¡é˜Ÿåˆ—å’Œäº‹ä»¶
            frame_queue = queue.Queue()
            stop_event = threading.Event()
            record_event = threading.Event()

            # å¯åŠ¨æ£€æµ‹çº¿ç¨‹
            detection_thread = threading.Thread(
                target=camera_detection_loop,
                args=(st.session_state.model, conf_threshold, frame_queue, stop_event, record_event)
            )
            detection_thread.start()

            # ä¸»çº¿ç¨‹å¤„ç†ç”»é¢æ›´æ–°
            start_time = time.time()

            while st.session_state.detection_active:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if stop_btn:
                    stop_event.set()
                    st.session_state.detection_active = False
                    st.session_state.recording_active = False
                    record_event.clear()

                # æ£€æŸ¥å½•åˆ¶çŠ¶æ€
                if record_btn:
                    st.session_state.recording_active = not st.session_state.recording_active
                    if st.session_state.recording_active:
                        record_event.set()
                    else:
                        record_event.clear()
                    time.sleep(0.5)  # é˜²æ­¢é‡å¤è§¦å‘

                # è·å–å¤„ç†ç»“æœ
                try:
                    item = frame_queue.get(timeout=0.1)

                    if item[0] == "frame":
                        _, frame, stats, frame_count, fps = item
                        # æ˜¾ç¤ºç”»é¢
                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                        frame_placeholder.image(frame_rgb, use_container_width=True)

                        # æ˜¾ç¤ºç»Ÿè®¡
                        if show_stats and stats:
                            with stats_placeholder.container():
                                st.subheader("å®æ—¶æ£€æµ‹ç»Ÿè®¡")
                                stats_df = pd.DataFrame(list(stats.items()), columns=["æ–‡æœ¬ç±»åˆ«", "æ£€æµ‹æ¬¡æ•°"])
                                st.dataframe(stats_df, use_container_width=True)

                    elif item[0] == "error":
                        frame_placeholder.error(item[1])
                        break

                    elif item[0] == "recording_complete":
                        _, recorded_video_path, stats, frame_count, fps = item
                        st.session_state.camera_recording_result = {
                            "video_path": recorded_video_path,
                            "stats": stats,
                            "frame_count": frame_count,
                            "fps": fps
                        }

                    elif item[0] == "done":
                        break

                except queue.Empty:
                    continue

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            detection_thread.join()
            end_time = time.time()

            # æ˜¾ç¤ºç»“æŸä¿¡æ¯
            frame_placeholder.info(f"æ£€æµ‹å·²åœæ­¢ | æŒç»­æ—¶é—´: {end_time - start_time:.2f}ç§’")

            # å¤„ç†å½•åˆ¶æ–‡ä»¶ï¼ˆä¸å…¶ä»–æ£€æµ‹ä¿æŒä¸€è‡´çš„ä¿å­˜é€»è¾‘ï¼‰
            if st.session_state.camera_recording_result:
                with stats_placeholder.container():
                    st.success("å½•åˆ¶å·²å®Œæˆ")

                    # ä¿å­˜é€‰é¡¹
                    if st.button("ä¿å­˜å½•åˆ¶ç»“æœ", use_container_width=True):
                        with st.spinner("æ­£åœ¨ä¿å­˜ç»“æœ..."):
                            result = st.session_state.camera_recording_result
                            media_path, meta_path = save_camera_recording(
                                result["video_path"],
                                result["stats"],
                                result["frame_count"],
                                result["fps"]
                            )
                            st.success(f"å½•åˆ¶ç»“æœå·²ä¿å­˜è‡³: {media_path}")

                            with open(media_path, "rb") as f:
                                st.download_button(
                                    "ä¸‹è½½å½•åˆ¶è§†é¢‘",
                                    f,
                                    file_name=os.path.basename(media_path),
                                    use_container_width=True
                                )

        elif start_btn and not st.session_state.model:
            frame_placeholder.warning("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
        elif start_btn and st.session_state.detection_active:
            frame_placeholder.info("æ£€æµ‹å·²åœ¨è¿›è¡Œä¸­")
        else:
            frame_placeholder.info("ç‚¹å‡»å¼€å§‹æ£€æµ‹æŒ‰é’®å¯åŠ¨æ‘„åƒå¤´")


if __name__ == "__main__":
    main()
